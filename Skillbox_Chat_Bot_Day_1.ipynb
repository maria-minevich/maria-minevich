{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skillbox Chat Bot Day 1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maria-minevich/maria-minevich/blob/main/Skillbox_Chat_Bot_Day_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Выводить текст на экран\n",
        "2.   Принимать данные на вход\n",
        "\n",
        "\n",
        "Чат Бот:\n",
        "*    Строчка текста на вход\n",
        "*    Строчка текста на выход"
      ],
      "metadata": {
        "id": "TR4xYJAMIWbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaydE8AFGLs6",
        "outputId": "5ab2e741-d5b8-4e96-9fd5-6d80e6b95040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всем приветы в этом чате\n"
          ]
        }
      ],
      "source": [
        "print(\"Всем приветы в этом чате\") # Shift+Enter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = input()\n",
        "if text == \"Привет\":\n",
        "  print(\"Здрасте\")\n",
        "\n",
        "if text == \"Пока\":\n",
        "  print(\"Ну и до свидания\")\n",
        "\n",
        "\n",
        "\n",
        "# Обработать случаи неточного совпадения\n",
        "# Две фразы? Сделать словарь для бота\n",
        "# Изучить Питон"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjk-9FJcIKTP",
        "outputId": "92fd4c58-c7f4-4fab-ea96-d66458defaf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Привет\n",
            "Здрасте\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # Regular Expressions\n",
        "import nltk # Natural Language Toolkit\n",
        "\n",
        "def filter_text(text):\n",
        "  text = text.lower()\n",
        "  pattern = r'[^\\w\\s]'\n",
        "  text = re.sub(pattern, \"\", text)\n",
        "  return text\n",
        "\n",
        "# На вход: два текста, на выход: boolean(True, False) \n",
        "# Функция isMatch вернет True, если тексты совпадают или False иначе\n",
        "def is_match(text1, text2):\n",
        "  # text1 = text1.lower()  # Приводим к нижнему регистру (\"ПрИвет\" => \"привет\")\n",
        "  # text2 = text2.lower()\n",
        "\n",
        "  # # Удаление знаков препинания\n",
        "  # # = Удалить все кроме букв и пробелов\n",
        "  # pattern = r'[^\\w\\s]'\n",
        "  # text1 = re.sub(pattern, \"\", text1) # Делать замену символов в строке\n",
        "  # text2 = re.sub(pattern, \"\", text2)\n",
        "  text1 = filter_text(text1)\n",
        "  text2 = filter_text(text2)\n",
        "\n",
        "  if len(text1) == 0 or len(text2) == 0:\n",
        "    return False\n",
        "    \n",
        "  # Проверить что одна фраза является частью другой\n",
        "\n",
        "  # Text1 содержит text2\n",
        "  if text1.find(text2) != -1:\n",
        "    return True\n",
        "  \n",
        "  # Text2 содержит text1\n",
        "  if text2.find(text1) != -1:\n",
        "    return True\n",
        "\n",
        "  # Расстояние Левенштейна (edit distance = расстояние редактирования)\n",
        "  distance = nltk.edit_distance(text1, text2)  # Кол-во символов 0...Inf\n",
        "  length = (len(text1) + len(text2))/2  # Средняя длина двух текстов\n",
        "  score = distance / length  # 0...1\n",
        "\n",
        "  return score < 0.6"
      ],
      "metadata": {
        "id": "HYl68Q0WJRwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сколько символов нужно отредактировать \"мама\" = (1) => \"мамы\"\n",
        "nltk.edit_distance(\"Привет братан\", \"Превед бротан\")\n",
        "# 0, 1, 2, 3...\n",
        "# 0 ... 0.3 ... 0.5 ... 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFxh0iTxXrM9",
        "outputId": "c9f16919-1c4d-4119-f08e-54d790d13d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Намерения = Intents\n",
        "# Поздароваться, спросить как дела, спросить имя или чем занимаешься\n",
        "# Заказать пиццу, отменить заказ, добавить больше сыра\n",
        "\n",
        "# Конфигурация бота\n",
        "BOT_CONFIG = {\n",
        "    # Все намерения которые поддерживает наш бот\n",
        "    \"intents\": {\n",
        "        \"hello\": {\n",
        "            \"examples\" : [\"Привет\", \"Здарова\", \"Йо\", \"Приветос\", \"Хеллоу\"],\n",
        "            \"responses\": [\"Здравстсвтсвтвтвуй человек\", \"И тебе не хворать\", \"Здоровее видали\"],\n",
        "        },\n",
        "        \"how_are_you\": {\n",
        "            \"examples\" : [\"Как дела\", \"Чо каво\", \"Как поживаешь\"],\n",
        "            \"responses\": [\"Маюсь Фигней\", \"Веду интенсивы\", \"Учу Пайтон\"],\n",
        "        }\n",
        "    },\n",
        "    # Фразы когда бот не может ответить\n",
        "    \"failure_phrases\": [\"Даже не знаю что сказать\", \"Поставлен в тупик\", \"Перефразируйте, я всего лишь бот\"],\n",
        "}\n",
        "\n",
        "def printAnswer(text, examples, responses):\n",
        "  for example in examples:  # Для каждого элемента списка examples\n",
        "    if isMatch(text, example):  # Если пример совпадает с текстом пользователя\n",
        "      print(random.choice(responses))  # Выводим на экран случайный элемент списка responses\n",
        "\n",
        "text = input()\n",
        "\n",
        "# Для каждого намерения, пытаемся напечатать ответ\n",
        "for intent in BOT_CONFIG[\"intents\"].values():\n",
        "    printAnswer(text, intent[\"examples\"], intent[\"responses\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhoZdXhTL8Yk",
        "outputId": "3ed40939-db0e-4914-a663-14034a634cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Приветик дорогой друг, как поживаешь вообще как дела?\n",
            "И тебе не хворать\n",
            "Веду интенсивы\n",
            "Учу Пайтон\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# День 2\n",
        "\n",
        "Скачать: [big_bot_config.json](https://drive.google.com/file/d/1_L5CYGsO58zkB3LMBG73ezIEwYFD07Ed/view)\n"
      ],
      "metadata": {
        "id": "oDLZvGGGCHug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "config_file = open(\"/content/big_bot_config.json\", \"r\")\n",
        "BIG_CONFIG = json.load(config_file)"
      ],
      "metadata": {
        "id": "JRmGMy9AP5tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BIG_CONFIG.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GfgBYgNQm9p",
        "outputId": "ec8c7a98-7228-4a88-b32f-d1ff5995fb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['intents', 'failure_phrases'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(BIG_CONFIG[\"intents\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcDQSflPQs13",
        "outputId": "e91d9df9-582b-4190-a290-59d68f8f665f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "439"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача**: Научить Модель Машинного Обучения определять intent (намерение) по тексту пользователя\n",
        "\n",
        "\n",
        "строчку на вход - строчку на выход\n",
        "X (входные данные) - y(выходные)\n",
        "ML-модель по входным данным может предсказать выходные данные\n",
        "\n",
        "\n",
        "Входные данные (X) - фразы\n",
        "Выходные данные (y) - намерения\n",
        "\n",
        "\n",
        "Модель обучится на наших примерах\n",
        "И сможет предсказывать намерения по входной фразе\n"
      ],
      "metadata": {
        "id": "kNikDFpQQ0Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = [] # Фразы\n",
        "y = [] # Намерения\n",
        "\n",
        "# Собираем фразы и интенты из BIG_CONFIG в X,y\n",
        "for name, intent in BIG_CONFIG[\"intents\"].items():\n",
        "  for example in intent[\"examples\"]:\n",
        "    X.append(example)\n",
        "    y.append(name)\n",
        "  for example in intent[\"responses\"]:\n",
        "    X.append(example)\n",
        "    y.append(name)\n",
        "\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEp2xbDESGT-",
        "outputId": "4cde17db-67f0-4a4c-b9d8-3b589b5e916e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5726"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка данных к обучению модели\n",
        "# NLP = Natural Language Processing\n",
        "\n",
        "# Векторайзер = превращает тексты в наборы чисел (вектора)"
      ],
      "metadata": {
        "id": "duaZXHgwTmxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)"
      ],
      "metadata": {
        "id": "BFFzYidKURoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "O5RE1XDpULd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Мама круто мыла раму => [1,2,3,4]\n",
        "# Круто мама раму мыла => [2,1,4,3]\n",
        "# Мыла мама круто раму => [3,1,2,4] "
      ],
      "metadata": {
        "id": "QNEZq5TOVK4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer() # Можно указать настройки\n",
        "vectorizer.fit(X) # Учится вот эти конкретные тексты превращать в числа"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WACkcN4iV_pO",
        "outputId": "ab0708a6-7e41-4a87-d80c-2fc65d56d59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = vectorizer.transform([\"друг друг друг друг привет\"]).toarray()[0]\n",
        "for a in arr:\n",
        "  if a!=0:\n",
        "    print(a, end=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3sQedQ8WQM6",
        "outputId": "29933526-a567-4a6f-b287-1a656e081534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4,1,"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1qZmOWySa5zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "0R1ant9CXTR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Классификация текста = предсказания класса(интент) по тексту(фразе)\n",
        "model = LogisticRegression() # Настройки\n",
        "vecX = vectorizer.transform(X) # Преобразуем тексты в вектора\n",
        "model.fit(vecX, y)  # Обучаем модель\n",
        "model.score(vecX, y)\n",
        "# Насколько качественно обучилась модель?\n",
        "# Пробуем разные модели, разные настройки"
      ],
      "metadata": {
        "id": "MX-uwNcfXyvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier() # Настройки\n",
        "vecX = vectorizer.transform(X) # Преобразуем тексты в вектора\n",
        "model.fit(vecX, y)  # Обучаем модель\n",
        "model.score(vecX, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suzoVgp7adAS",
        "outputId": "8614b299-f68f-433e-d050-f88da2908016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8643031784841075"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPClassifier(max_iter=500, hidden_layer_sizes=(100,100,100,)) # Настройки\n",
        "vecX = vectorizer.transform(X) # Преобразуем тексты в вектора\n",
        "model.fit(vecX, y)  # Обучаем модель\n",
        "model.score(vecX, y)"
      ],
      "metadata": {
        "id": "lDCNgG5sc4VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7dx9elE5fq0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def get_intent_ml(text):\n",
        "  vec_text = vectorizer.transform([text]) \n",
        "  intent = model.predict(vec_text)[0]\n",
        "  # ToDo: выдавать ответ только если модель уверена в нем\n",
        "  return intent\n",
        "\n",
        "def get_intent(text):\n",
        "  for name, intent in BIG_CONFIG[\"intents\"].items():\n",
        "    for example in intent[\"examples\"]:\n",
        "      if is_match(text, example):\n",
        "        print(f\"name={name} example={example}\")\n",
        "        return name\n",
        "\n",
        "  return None\n",
        "\n",
        "def bot(phrase):\n",
        "  phrase = filter_text(phrase)\n",
        "  # Напрямую найти ответ\n",
        "  intent = get_intent(phrase)\n",
        "  \n",
        "  # Если напрямую интент не нашелся\n",
        "  if not intent:\n",
        "    # Попросить модель найти ответ\n",
        "    intent = get_intent_ml(phrase)\n",
        "\n",
        "  # Если намерение определено\n",
        "  if intent:\n",
        "    responses = BIG_CONFIG[\"intents\"][intent][\"responses\"] # Находим варианты ответов\n",
        "    return random.choice(responses)\n",
        "  \n",
        "  failure = BIG_CONFIG[\"failure_phrases\"]\n",
        "  return random.choice(failure)\n",
        "  # Выдать Failure Phrase\n",
        "\n",
        "# filter_text\n",
        "# is_match\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nWVKI0NRfPmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  vec_text = vectorizer.transform([\"синхрофазатрон\"]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCrQ1TWFlQ2g",
        "outputId": "d6c00150-4b3f-4f33-c960-a4144ae991b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x6545 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 0 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# proba = model.predict_proba(vec_text)[0]\n",
        "# intent = model.predict(vec_text)[0]\n",
        "# for i in range(0, len(model.classes_)):\n",
        "#   cls=model.classes_[i]\n",
        "#   if cls == intent:\n",
        "#     print(\"Intent: \", intent)\n",
        "#     print(\"Probability: \", proba[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXlE7IznllJP",
        "outputId": "44b1dcfe-d639-4420-b64c-7ae03a2f092d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent:  digit_guess\n",
            "Probability:  0.3155207731038464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot(\"как тебя зовут пацан\")"
      ],
      "metadata": {
        "id": "vi-zCzrff3Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BIG_CONFIG[\"intents\"][\"location\"][\"examples\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQXhdVognJYN",
        "outputId": "14ad6021-a248-4ba6-c14c-00f91a57d7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Где ты находишься', 'Где ты живешь', 'Ты где']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_intent(\"ты где\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8Ok6_PhdncD3",
        "outputId": "7c8da0fe-9692-4881-ebe4-e2f9b665b93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name=mood example=Ты как\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mood'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg = \"\"\n",
        "exit_phrases = [\"Выйти\", \"Выключись\", \"Bye\", \"Пока\"]\n",
        "\n",
        "while not msg in exit_phrases:\n",
        "  msg = input()\n",
        "  print(\"[BOT]: \" + bot(msg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahX3x4Z5jOtn",
        "outputId": "80a95868-f5d5-4a22-9163-355aa22e559e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ты приличный?\n",
            "name=bad_questions example=ты глупый\n",
            "[BOT]: Я быстро учусь\n",
            "Пока\n",
            "name=bye example=пока\n",
            "[BOT]: На связи\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wG3YMumGPfmf"
      }
    }
  ]
}